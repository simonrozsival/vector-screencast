\chapter{Programmers docummentation}

\section{Compiling and using the library}

Source code of the project can be found either on the attached CD, or in git repository \textit{https://github.com/simonrozsival/vectorvideo}. Copy or clone this code to your computer.

To be able to compile the library, it is necessary to install \textit{Node.js}\footnote{https://nodejs.org/} on your computer. After installing Node.js, install all dependencies of this project by running the \verb|npm install| command in the root directory of the project's source files. You must also install \textit{Gulp} streaming build system\footnote{http://gulpjs.com} globaly by running the \verb|npm install -g gulp| command.

Build all code by running \verb|gulp| command in the same directory. This will compile all TypeScript source files into JavaScript. You can then use the compiled and minified library located in \textit{./release/vector-screencast/vector-screencast.min.js} JavaScript file. Along with the library, a web worker file \textit{./release/workers/RecordingWorker.js}, which is necessary for audio recording. Default CSS theme of the player and recorder was compiled from LESS source to \textit{./release/themes/default/theme.min.css}.

A demo audio recording server was also compiled in this process and is available in the \textit{./release/audio-server/AudioServer.js} JavaScript file. This server can used in a Node.js program.

For details on how to use the library in your project, see chapter \textit{Integration} (@todo - link).



\section{Event driven programming}
The idea behind event driven programming is to break direct references between objects and to communicate with \textit{events} instead of calling object methods directly. The advantage of the this approach is loose coupling \footnote{http://en.wikipedia.org/wiki/Coupling\_(computer\_programming)} -- features might be added or removed without breaking the core of the application.

Each object handles only it's own task without knowing anything about the other objects it's collaborating with. When an object completes it's task, it publishes the result with a specific event. Objects subscribed for this event are notified and are given the outcomes of the previous task.

This mechanism is sometimes called the \textit{Event Aggregator} design pattern \cite{}. It is implemented through the \textit{VideoEvents}\footnote{Implementation can be found in \textit{/public/js/app/Helpers/VideoEvents.ts} file} static class, which makes it a simple singleton object. This class provides an interface for registering and triggering callbacks for specified events. Callbacks executed by a triggered event are called asynchronously. It is worth mentioning that web browsers execute all scripts in a single thread.

\begin{verbatim}
VideoEvents.on(VideoEventType.Message, function(message) {
	console.log("received message:", message);
});

VideoEvents.on(VideoEventType.Message, function(message) {
	console.log("received message backwards:", message.split("").reverse().join(""));
});

VideoEvents.trigger(VideoEventType.Message, "Hello world.");
\end{verbatim}





\subsubsection{Audio capturing, processing and upload}

HTML5 provides only one way to access microphone data at the moment and it is through the \textit{getUserMedia API} \footnote{getUserMedia: http://www.w3.org/TR/mediacapture-streams/\#dom-mediadevices-getusermedia} \cite{}. \textit{navigator.getUserMedia} function prompts the user to for permission to use their audio input (this function is also used to access webcam stream in other applications). The \textit{navigator.getUserMedia} function is well documented on Mozilla Developer Network (MDN) \footnote{MDN: https://developer.mozilla.org/en-US/docs/Web/API/Navigator/getUserMedia} website.

If user's device has a connected microphone and user gives his permission to use his audio input, then a \textit{MediaStream} \footnote{MediaStream: http://www.w3.org/TR/mediacapture-streams/\#idl-def-MediaStream} object is provided by the browser and from this time on audio can be captured. Error callback with \textit{MediaStreamError}\footnote{MediaStreamError: http://www.w3.org/TR/mediacapture-streams/\#idl-def-MediaStreamError} instance is called otherwise.

Once the \textit{MediaStream} is obtained, 





All this logic is wrapped inside the \textit{AudioRecorder} class in the \textit{AudioData} module.


\subsubsection{High Resolution Timer}
To make the video look as good as possible, we need to store as precise data as possible. The \textit{Date.now()} function\footnote{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global\_Objects/Date/now} returns the number of milliseconds elapsed since 1 January 1970 00:00:00 UTC. The millisecond accuracy might seem enough, but modern browsers provide even more accurate data via the \textit{High Resolution Time} \footnote{https://dvcs.w3.org/hg/webperf/raw-file/tip/specs/HighResolutionTime/Overview.html} via the \textit{window.performance.now()} function\footnote{https://developer.mozilla.org/en-US/docs/Web/API/Performance/now} \footnote{http://updates.html5rocks.com/2012/08/When-milliseconds-are-not-enough-performance-now} with the accuracy of microseconds. The \textit{window.performance.now()} function doesn't provide data related to current time, but the milliseconds elapsed since page was loaded as a floating point number. This makes it more suitable for animation purposes.

Timing functionality is wrapped in \textit{VideoTimer} class in the Helpers module\footnote{implementation can be found in \textit{/src/VectorVideo/Helpers/VideoTimer.ts} file with a method for getting the number of milliseconds elapsed since last timer reset with the best precision provided by the web browser.






\subsubsection{Input from pointing devices}

Detecting mouse movement and the state of it's buttons is a very common task in web development. Users navigate through web pages mainly by clicking on hypertext links with their computer mouse. Therefore mouse events are well specified and work across all desktop web browsers and desktop platforms.

Unfortunately, the situation among other pointing devices other than computer mice is much less uniform. With the boom of smartphones and tablets, touchscreens are very common. Also computer graphics tablets are used by artists and many people use them when creating a Khan Academy style video.

\paragraph{Mouse input}
Event handler is passed the \textit{MouseEvent} object\footnote{http://www.w3.org/TR/DOM-Level-2-Events/events.html#Events-MouseEvent}. The relevat information are the \textit{clientX} and \textit{clientY} properties, stating current mouse posititon relative to the position of the element it is attached to. 

\paragraph{Wacom Webplugin pen API}
The Wacom Webplugin pen API (WebPAPI) is a browser plugin interface for pen data access from all Wacom consumer and professional tablets \cite{}\footnote{http://www.wacomeng.com/web/WebPluginReleaseNotes.htm}.

Unfortunatelly support for this plugin was discontinued by Chromium and Google Chrome \footnote{http://blog.chromium.org/2013/09/saying-goodbye-to-our-old-friend-npapi.htm} and therefore it should not be relied on.

\paragraph{Touch Events API}
Touch Events API is an API for handling touch input from touch screens. The standard is proposed by Apple and is implemented across many platforms and in many mobile web browsers \footnote{http://caniuse.com/\#feat=touch} \cite{}.

This API supports multiple touches at once, but this feature is not needed and neither implemented in this project. Unfortunately, this API provides no touch pressure information.

\paragraph{Pointer Events API}
Pointer Events API is an open API created by Microsoft. It's purpose is to unify the way mouse events, touch screen events, stylus and other (i.e. Kinect) similar ways into one API. This technology is implemented in Internet Explorer and will be also present in the final version of the Microsoft Edge browser. Firefox implements this API, but it is so far accessible only if a specific hidden flag is enabled. Google has announced the intent to also implement this functionality in upcoming releases of Google Chrome across all platforms.

This API also provides pressure information for pointing devices, that support this feature, including Wacom graphics tablets.